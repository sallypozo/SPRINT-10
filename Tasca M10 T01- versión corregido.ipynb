{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0da0bb47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('“The world as we have created it is a process of our thinking. It cannot be changed without changing our thinking.”', 'Albert Einstein')\n",
      "('“It is our choices, Harry, that show what we truly are, far more than our abilities.”', 'J.K. Rowling')\n",
      "('“There are only two ways to live your life. One is as though nothing is a miracle. The other is as though everything is a miracle.”', 'Albert Einstein')\n",
      "('“The person, be it gentleman or lady, who has not pleasure in a good novel, must be intolerably stupid.”', 'Jane Austen')\n",
      "(\"“Imperfection is beauty, madness is genius and it's better to be absolutely ridiculous than absolutely boring.”\", 'Marilyn Monroe')\n",
      "('“Try not to become a man of success. Rather become a man of value.”', 'Albert Einstein')\n",
      "('“It is better to be hated for what you are than to be loved for what you are not.”', 'André Gide')\n",
      "(\"“I have not failed. I've just found 10,000 ways that won't work.”\", 'Thomas A. Edison')\n",
      "(\"“A woman is like a tea bag; you never know how strong it is until it's in hot water.”\", 'Eleanor Roosevelt')\n",
      "('“A day without sunshine is like, you know, night.”', 'Steve Martin')\n"
     ]
    }
   ],
   "source": [
    "#Ejercicio 1: \n",
    "\n",
    "#Realiza web scraping de dos de las tres páginas web propuestas utilizando BeautifulSoup primero y Selenium después. \n",
    "# http://quotes.toscrape.com\n",
    "# https://www.bolsamadrid.es\n",
    "# www.wikipedia.es (haz alguna búsqueda primero y aplasta algún contenido)\n",
    "#------------------------------------------\n",
    "#BEATIFULSOUP: http://quotes.toscrape.com\n",
    "import requests\n",
    "import csv\n",
    "from bs4 import BeautifulSoup\n",
    "# Dirección de la página web\n",
    "url = \"http://quotes.toscrape.com/\"\n",
    "# Ejecutar GET-Request\n",
    "response = requests.get(url)\n",
    "# Analizar sintácticamente el archivo HTML de BeautifulSoup del texto fuente\n",
    "html = BeautifulSoup(response.text, 'html.parser')\n",
    "# Extraer todas las citas y autores del archivo HTML\n",
    "quotes_html = html.find_all('span', class_=\"text\")\n",
    "authors_html = html.find_all('small', class_=\"author\")\n",
    "# Crear una lista de las citas\n",
    "quotes = list()\n",
    "for quote in quotes_html:\n",
    "    quotes.append(quote.text)\n",
    "# Crear una lista de los autores\n",
    "authors = list()\n",
    "for author in authors_html:\n",
    "    authors.append(author.text) \n",
    "# Para hacer el test: combinar y mostrar las entradas de ambas listas\n",
    "for i in zip(quotes, authors):\n",
    "    print(i)\n",
    "# Guardar las citas y los autores en un archivo CSV en el directorio actual\n",
    "# Abrir el archivo con Excel / LibreOffice, etc.\n",
    "with open('./zitate.csv', 'w') as csv_file:\n",
    "    csv_writer = csv.writer(csv_file, dialect='excel')\n",
    "    csv_writer.writerows(zip(quotes, authors))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cb645aca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('APERTURAS DE HONOR', 'Toques de Campana')\n",
      "('Informe', 'Informe sobre la propiedad de las acciones cotizadas')\n",
      "('EDUCACIÓN FINANCIERA', 'Día de la Educación Financiera')\n"
     ]
    }
   ],
   "source": [
    "#Ejercicio 1: # https://www.bolsamadrid.es(BEATIFULSOUP)\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "# Importar módulos\n",
    "import requests\n",
    "import csv\n",
    "from bs4 import BeautifulSoup\n",
    "# Dirección de la página web\n",
    "url2 = \"https://www.bolsamadrid.es\"\n",
    "# Ejecutar GET-Request\n",
    "response = requests.get(url2)\n",
    "# Analizar sintácticamente el archivo HTML de BeautifulSoup del texto fuente\n",
    "html2 = BeautifulSoup(response.text, 'html.parser')\n",
    "# Extraer todas las citas y autores del archivo HTML\n",
    "titulos_html = html2.find_all('span', class_=\"section-banners-image-title\")\n",
    "contents_html = html2.find_all('h3', class_=\"section-banners-title\")\n",
    "# Crear una lista de las citas\n",
    "titulos = list()\n",
    "for titulo in titulos_html:\n",
    "    titulos.append(titulo.text)\n",
    "# Crear una lista de los autores\n",
    "contents = list()\n",
    "for content in contents_html:\n",
    "    contents.append(content.text) \n",
    "# Para hacer el test: combinar y mostrar las entradas de ambas listas\n",
    "for i in zip(titulos, contents):\n",
    "    print(i)\n",
    "# Guardar las citas y los autores en un archivo CSV en el directorio actual\n",
    "# Abrir el archivo con Excel / LibreOffice, etc.\n",
    "with open('./zitate.csv', 'w') as csv_file:\n",
    "    csv_writer = csv.writer(csv_file, dialect='excel')\n",
    "    csv_writer.writerows(zip(titulos, contents))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "94197335",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WDM] - Downloading: 100%|██████████| 6.79M/6.79M [00:00<00:00, 30.2MB/s]\n"
     ]
    }
   ],
   "source": [
    "#Ejercicio 1: # http://quotes.toscrape.com(Selenium)\n",
    "#Step1: – Import libraries\n",
    "import os\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "import time\n",
    "from PIL import Image\n",
    "import io\n",
    "import requests\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.common.exceptions import ElementClickInterceptedException\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "#Step 2: – Install Driver\n",
    "#Install Driver\n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()))\n",
    "driver.get(\"https://www.google.com\")\n",
    " \n",
    "#Step 3: –  Specify search URL\n",
    "#Specify Search URL \n",
    "search_url= \"http://quotes.toscrape.com\" \n",
    "\n",
    "driver.get(search_url.format(q='thinking'))\n",
    "\n",
    "#Step 4: –  Scroll to the end of the page\n",
    "#Scroll to the end of the page\n",
    "driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "time.sleep(5)#sleep_between_interactions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e2764196",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ejercicio 1: # https://www.bolsamadrid.es(Selenium)\n",
    "\n",
    "import os\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "import time\n",
    "from PIL import Image\n",
    "import io\n",
    "import requests\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.common.exceptions import ElementClickInterceptedException\n",
    " \n",
    "\n",
    "#Install Driver\n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()))\n",
    "driver.get(\"https://www.google.com\")\n",
    " \n",
    "#Step 3: –  Specify search URL\n",
    "#Specify Search URL \n",
    "search_url= \"https://www.bolsamadrid.es\" \n",
    "\n",
    "driver.get(search_url.format(q='Informe'))\n",
    "\n",
    "#Step 4: –  Scroll to the end of the page\n",
    "#Scroll to the end of the page\n",
    "driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "time.sleep(5)#sleep_between_interactions\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14cac2ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejercicio 2\n",
    "# Documenta en un Word tu conjunto de datos generado con la información que tienen los distintos archivos de Kaggle.\n",
    "\n",
    "= Csv.Document(Web.Contents(\"https://www.kaggle.com/datasets/vivovinco/20212022-football-team-stats\"),[Delimiter=\",\", Encoding=65001, QuoteStyle=QuoteStyle.None])\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "89596801",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search Results\n",
      "There are 12 t-shirts on the page.\n"
     ]
    }
   ],
   "source": [
    "#Ejercicio 3\n",
    "#Elige una página web que quieras y realiza web scraping mediante la librería Selenium. \n",
    "#libreria Selenium\n",
    "# Import the library Selenium\n",
    "import os\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "import time\n",
    "from PIL import Image\n",
    "import io\n",
    "import requests\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.common.exceptions import ElementClickInterceptedException\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "#Step 2: – Install Driver\n",
    "#Install Driver\n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()))\n",
    "driver.get(\"https://www.google.com\")\n",
    " \n",
    "#Step 3: –  Specify search URL\n",
    "#Specify Search URL \n",
    "search_url= \"http://www.montypythononlinestore.com/\" \n",
    "\n",
    "driver.get(search_url.format(q='t-shirt'))\n",
    "\n",
    "#Step 4: –  Scroll to the end of the page\n",
    "#Scroll to the end of the page\n",
    "driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "time.sleep(5)#sleep_between_interactions\n",
    "\n",
    "\n",
    "#we get the internal html code of the body\n",
    "body = driver.execute_script(\"return document.body\")\n",
    "source = body.get_attribute('innerHTML')\n",
    "# Interactuando con elementos\n",
    "search_box = driver.find_element(By.ID, \"search-field\")\n",
    "search_box.send_keys(\"t-shirt\")\n",
    "search_box.send_keys(Keys.ENTER)\n",
    "\n",
    "wait = WebDriverWait(driver, 10)\n",
    "element = wait.until(EC.presence_of_element_located((By.TAG_NAME, \"h2\")))\n",
    "\n",
    "element_text = element.text\n",
    "print(element_text)\n",
    "\n",
    "all_products = driver.find_elements(By.CLASS_NAME, 'product')\n",
    "print(f'There are {len(all_products)} t-shirts on the page.')\n",
    "\n",
    "driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "time.sleep(5)\n",
    "driver.save_screenshot(\"screenshot.png\")\n",
    "\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "69197021",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scrapy.item import Field\n",
    "from scrapy.item import Item\n",
    "from scrapy.spiders import Spider\n",
    "from scrapy.selector import Selector\n",
    "from scrapy.loader.processors import MapCompose\n",
    "from scrapy.loader import ItemLoader\n",
    "from bs4 import BeautifulSoup\n",
    "from scrapy.crawler import CrawlerProcess\n",
    "\n",
    "# ABSTRACCION DE DATOS A EXTRAER - DETERMINA LOS DATOS QUE TENGO QUE LLENAR Y QUE ESTARAN EN EL ARCHIVO GENERADO\n",
    "class Noticia(Item):\n",
    "    id = Field()\n",
    "    titular = Field()\n",
    "    descripcion = Field()\n",
    "\n",
    "\n",
    "# CLASE CORE - SPIDER  \n",
    "class ElUniversoSpider(Spider):\n",
    "    name = \"MiSegundoSpider\"\n",
    "    custom_settings = {\n",
    "        'USER_AGENT': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Ubuntu Chromium/71.0.3578.80 Chrome/71.0.3578.80 Safari/537.36',\n",
    "        # 'FEED_EXPORT_FIELDS': ['id', 'descripcion', 'titular'], # Como ordenar las columnas en el CSV?\n",
    "        # 'CONCURRENT_REQUESTS': 1 # numero de requerimientos concurrentes \n",
    "        #'FEED_EXPORT_ENCODING': 'utf-8'\n",
    "    }\n",
    "    start_urls = ['https://www.eluniverso.com/deportes']\n",
    "\n",
    "    def parse(self, response):\n",
    "        sel = Selector(response)\n",
    "        noticias = sel.xpath('//div[contains(@class, \"content-feed\")]/ul/li')\n",
    "        for i, elem in enumerate(noticias): # PARA INVESTIGAR: Para que sirve enumerate?\n",
    "            item = ItemLoader(Noticia(), elem) # Cargo mi item\n",
    "\n",
    "            # Llenando mi item a traves de expresiones XPATH\n",
    "            item.add_xpath('titular', './/h2/a/text()')\n",
    "            item.add_xpath('descripcion', './/p/text()')\n",
    "            item.add_value('id', i)\n",
    "            yield item.load_item() # Retorno mi item lleno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c3022a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f7bf31",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c668f96a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f679a54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c370a2ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a491ce5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fbdca38",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
